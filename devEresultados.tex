%% ------------------------------------------------------------------------- %%
\chapter{Desenvolvimentos e resultados} %Nome do capítulo.
\label{cap:resultados} %Rótulo para futura referência ao capítulo. Em qualquer lugar da tese, você poderá citar este capítulo através de ~\ref{cap:introducao}. Você escolhe o argumento de \label e pode ser qualquer coisa (Ex: \label{Procedimento_Experimental})


\section{Áudio e Música}

Os resultados explicitados nesta dissertação estão focados no processamento de 
áudio voltado para a música e na síntese de estruturas musicais.

Por razões didáticas, dividimos este capítulo em 4 partes, a saber: experimentos
abertos em áudio e música (incluindo plugins LADSPA, Wavelets, Redes Complexas e outros
scripts experimentais), música em tempo diferido (ou seja, que não é feito em tempo real),
música em tempo real, e música na matéria (suporte físico em hardware).

Com isso, desejamos percorrer minimamente a prática musical através do código.
com exemplos reais de aplicação e em uso pelo autor, por membros do LabMacambira.sf.net,
por parceiros, colaboradores e por usuários eventuais das naturezas mais diversas.

  \subsection{Experimentos abertos em áudio: LADSPAs, Wavelets e Redes Complexas}

Todos os desenvolvimentos desta dissertação estão em repositórios abertos\cite{repositorios-tese-dev},
e alguns foram especialmente importantes como percurso para o que é apresentado neste
escrito. Ou seja, 

Focaremos no código para a arte sonora,
incluindo a musical, e portanto fazendo parte da cultura e fazendo cultura.
\footnote{As chamadas culturas biopunk, ciberpunk, cipherpunk, hacker, digital e outras mais,
possibilitadas aos recentes desenvolvimentos em telecomunicação, dizem respeito em menor
ou maior grau ao código.}

A seguir apresentamos alguns bons exemplos dos desenvolvimentos
desta dissertação especificamente em áudio, sem o envolvimento direto da música.

      \subsubsection{Plugins LADSPA e lv2}
      [repos AE, LM, wiki EL, historico CDTL]


      \subsubsection{Protocolo de compactação de áudio via wavelets, polinômios e permutações}
      [achar artigo feec]


      \subsubsection{Processamento de voz via redes complexas}
      [repo do audio experiments. passar para o LM e chamar o TT]
  



  \subsection{Musica em Tempo Diferido: Minimum-fi e FIGGUS}

\begin{quotation}
\small
'The increasing dominance of graphic interfaces for music software obscured 
the continuing presence of the command-line tradition, 
the code writer, the hacker. The code writing of deferred time 
computer programming may be assembled out of time order, debugged and optimized.'

\emph{Simon Emmerson, Living electronic music, 2007}
\end{quotation}

A realização musical em tempo diferido é o paradigma inicial da música computacional.
Iniciando com o Music V, a proposta foi depois desenvolvido com o CSound. Pode-se dizer
que até hoje é a forma como compositores usualmente pensam a música: pensando
e escrevendo as estruturas, que depois são executadas por instrumentistas ou aparelhos eletrônicos.

Assim como a composição instrumental permite um trabalho mais minucioso do que
a improvisação instrumental, a realização musical em tempo diferido usualmente permite um
detalhamento maior dos procedimentos do que a realização em tempo real. Por este
mesmo motivo, trataremos inicialmente de dois trabalhos em tempo diferido.
Aliás, como veremos a seguir, as abordagens são paradigmáticas para a música
computacional praticada até os dias de hoje.

O primeiro destes feitos, chamado de \emph{minimum-fi}\footnote{hi-fi, low-fi, minimum-fi, ou seja,
o mínimo de qualidade para assegurar existência e consistência
da criação} sintetiza uma música inteira, amostra por amostra, através de princípios
claros de síntese sonora e organização musical. O segundo, chamado de \emph{FIGGUS} (FInite
Groups in Granular and Unit Synthesis), utiliza os princípios do minimum-fi e constitui
um módulo Python completo, cuja proposta é a utilização de simetrias, através de
permutações e de Teoria de Grupos, para a composição de músicas. Como demonstração
das capacidades do FIGGUS, ele gera um EP (E... Play, pegar significado dele) inteiro com um único comando. Este é o
\emph{PPEPPS}\footnote{Pure Python EP: Projeto Solvente}, como veremos a seguir.

Desta forma, esta sessão exemplifica e explicita - através de dois exemplos reais - os
princípios do uso de código para a síntese \emph{musical}, desde as amostras
relativas a uma nota com dada frequencia, amplitude e timbre, até a confecção
de uma ferramenta derivada, já incorporando propostas musicais e estruturas
mais elaboradas.

      \subsubsection{Minimum-fi}

Em Abril de 2011 surgiu a necessidade estética e também tecnológica
de realizar um código dedicado a materializar \emph{o mínimo}
para expressar ideias musicais em geral. Esta empreitada
resultou no minimum-fi, código em um único arquivo, que sintetiza
músicas inteiras. Os algorítmos propriamente ditos, escritos em Python, somam 
53 linhas e inclui 5 funções. Com estas funções, estruturas musicais podem 
ser criadas amostra por amostra, resultando em notas, blocos e estruturas hierarquicamente superiores.

Os princípios, bastante simples, são:
\begin{itemize}
  \item Deve-se ter um mecanismo de síntese sonora que
permita vários timbres e controle sobre a frequência fundamental.
  \item Deve-se ser capaz de construir unidades e séries de unidades (notas e acordes, por exemplo).
\end{itemize}

Para o primeiro item, se prestam comumente os procedimentos de busca em tabelas/vetores com formas
de ondas em alta resolução (chamado \emph{lookup table}). O procedimento é barato e de qualidade alta
(não acrescentam ruídos relevantes ao sinal). A seguir está o procedimento da lookuptable:

\code{Procedimento de Lookup Table}{python_snippets/lookuptable.py}

O primeiro ponto importante é a tabela em si, usualmente unidimensional. É de comum conhecimento que
tabelas com 1024 são mais que suficientes para os usos musicais e a diferença
de qualidade (relação sinal/ruido) não muda consideravelmente com a utilização
de tabelas maiores. A seguir dispomos algumas destas tabelas, mais 
especificamente, dispomos as tabelas para os formatos de onda mais usuais. 

\code{Formas de Onda Tradicionais}{python_snippets/formasDeOnda.py}

Através da utilização do lookup sucessivo (procura-se um valor na primeira tabela
e este valor indica o valor na segunda tabela a ser utilizado), executamos
um waveshaping. Este procedimento é bastante apreciado pela simplicidade e eficácia
na síntese de tímbres diversos e ricos em harmônicos e evolução temporal.

[codigo do lookupcruz e explicacao]

O segundo item presta-se à discretização do espaço musical. Unidades como batidas e notas
tornam mais eficiente a comunicação pois a quantidade
de estruturas sugeridas é maior e as estruturas são mais claras~\cite{Roederer} no discreto do que no contínuo. Roederer
aponta que as próprias notas dos instrumentos musicais são um reflexo de que é mais eficiente
o uso do discreto do que do contínuo.

Desta forma, unidades bem definidas se mostram úteis na prática musical 
para fazer sequencias de unidades, concatená-las. Quando as unidades
são notas, as sequencias de unidades justapostas no tempo são melodias ou linhas melódicas. As
sequencias sobrepostas no tempo são comumente pensados como acordes, mas podem ser tidos simplesmente
como sobreposições circunstanciais de duas linhas melódicas. Isso, claro, segundo
a sistematização clássica e usual da música~\cite{Lacerda}.

As duas construções básicas explicitadas, baseadas na dicotomia melodia/harmonia
(horizontalidade/verticalidade, justaposição/sobreposição), são
as funções \emph{fazSequencia} e \emph{fazAcorde}. Vale notar elas são absolutamente 
equivalentes em uma análise puramente conceitual, i.e. uma delas pode ser omitida segundo
a teoria. Isso fica particularmente óbvio quando se nota que os procedimentos de mixagem e concatenação são
plenamente capazes de realizar o que estas funções realizam. Aliás, as funções nada
mais são do que usos típicos e quase caricatos destes procedimentos: no fazAcorde a mixagem
sobrepõe no tempo todas as unidades, no fazSequencia as unidades são todas juntapostas no tempo.

Como pode notar a seguir, as sequencias de notas e os acordes, em última instância, são utilizações específicas
das 2 funcoes de síntese sonora explicadas anteriormente: lookup e lookupcruz.

[codigo do fazSequencia e explicacao]

[codigo do fazAcorde e explicacao]

A última das cinco funções utilizadas é uma soma amostra a amostra de dois sons. Para isso,
é necessário completar com zeros a sequencia com o menor número de amostras:

[codigo do somador, explicacao e figura de uma sequencia maior/menor que a outra]

Depois disso é usufruir com estruturas criadas. Por exemplo: depois de construidas
algumas tabelas para serem usadas como diferentes timbres, pode-se criar as
escalas completamente simetricas assim:

\code{Escalas Simétricas na grade dos 12 semintos e no âmbito da oitava}{python_snippets/escalas_simetricas.py}

% escala\_1=range(12) # cromática ascendente sem inclusão da oitava
% escala\_2=range(0,12,2) # tons inteiros
% escala\_3=range(0,12,3) # diminutão
% escala\_4=range(0,12,4) # terças maiores
% escala\_6=range(0,12,6) # trítonos
% \end{python}
% \input{py}

Sendo cada unidade um semitom. Claro que podemos também utilizar as usuais
escalas tonais maior e menor natural, harmônica e melódica:

[codigo das escalas maior e menores]

A utilização de intervalos menores que o semitom\footnote{Prática também conhecida
como \emph{microtonalidade}} mostra-se trivial em
nossa implementação:

[escalas com intervalos microtonais]

Da mesma forma, as triades maiores e menores
são especificadas com simplicidade. Note que aos acordes \emph{diminutão} e
\emph{aumentado} correspodem as mesmas notas das escalas simetricas de terças menores
e maiores respectivamente:

\code{Acordes anotados como listas em python}{python_snippets/acordes.py}


E séries podem ser anotadas junto a variacoes:

\code{Séries diversas}{python_snippets/series.py}

Com este arcabouço, o passo seguinte é sintetizar e mixar, resultando
em sequências musicais. A síntese de sequências e acordes são feitos tipicamente
através de comandos desta forma:

\code{Sintetizando sequências e acordes}{python_snippets/seqs_acordes.py}
\code{Acordes periódicos}{python_snippets/acordes_periodicos.py}

Em posse destas sequências e acordes, formamos estruturas hierarquicamente superiores
através da concatenação de estruturas, da mixagem de estruturas, e da amplificação
(ou atenuação) seletiva das mesmas:

\code{Amplificação e mixagem}{python_snippets/amp_mix.py}



        \subsubsection{Finite Groups in Granular and Unit Synthesis (FIGGUS)}

Desenvolvimento iniciado em 2006 com o físico-matemático Prof. Adolfo Maia Junior para
tratar de simetrias na música, com vistas à composição musical através
de métodos matemáticos. Mais especificamente, a proposta resultou em
um programa voltado para o uso de Grupos Algébricos para síntese
granular e síntese de estruturas musicais. O nome dado
foi FIGGUS, sigla de FInite Groups in Granular and Unit Synthesis\footnote{Também utilizamos
o nome FIGGS (FInite Group in Granular Synthesis) dado que o termo \emph{unit synthesis} não
é usual na literatura. Posteriormente o principal autor deste trabalho recorreu novamente
ao FIGGUS pois o maior uso da abordagem é para síntese de estruturas musicais, não para
síntese de amálgamas sonoros tipicamente resultantes da síntese granular}.

A Síntese Granular é uma área bem estabelecida tanto na acústica quanto
na Computação Musical. O Físico Gabor, quantum sonoro, phonon, etc..
[achar artigos feitos com adolfo]

Na atual reescrita, embora ainda bastante atrás do FIGGUS original,
e mesmo sem a interface gráfica, o código roda inteiro em python
com as biblitecas imbutidas por padrão. Isso permite com que o FIGGUS
sintetize todo um EP usando somente os comandos:

[[ARRUMAR A PARADA PARA O CODIGO]]
git clone
python setup.py install
python RUNME

[Explicar o conceito de simetria e permutações]
[Expor sobre uma ou duas músicas feitas com o FIGGUS]

  \subsection{Música em Tempo Real: Livecoding e ABeatTracker (ABT)}

Com os avanços computacionais recentes, tornou-se usual a síntese sonora
em tempo real. Com isso, surgiram liguagens dedicadas para o áudio e a música
em sua maioria dedicadas - ou ao menos capacitadas - para o uso 
em tempo de execussão [citar PD, SC, ChucK]. Em outras palavras, estas linguagens
possibilitam que o usuário ouça o resultante sonoro do código utilizado e altere
o código com resultado imediato no processamento e resultado que escuta.

Nesta linha de exploração musical do código, iremos expor a seguir sobre
nossas investidas em \emph{Livecoding} (escrita de código em tempo real
com vistas à performance pública) e o ABeatTracker (uma linguagem por macros
para execussão sonora rítmica em conjunto com instrumentos tradicionais e outras
fontes sonoras/musicais externas).


        \subsubsection{Livecoding}

Recentemente, grupos de ponta em música experimental no mundo todo estão
desenvolvendo apresentações musicais públicas baseadas na escrita
de código ao vivo. Usualmente, se projeta o código para que a audiência possa
ver o que está sendo escrito, no rítmo em que se escreve, e se projeta também
o resultante sonoro por autofalantes.

As motivações para isso são variadas. Expomos a seguir de forma topificada
um condensado do que nos orientou a tal prática. Vale ressaltar que são
motivações igualmente presentes em outros grupos, embora não necessariamente
em todos ou da mesmícima forma.

\begin{itemize}
    \item A performance musical por computador carece de recursos performáticos
    à altura das execussões com instrumentos tradicionais. Os gestos são por demais
    discretos e a concentração do performer é bastante focada na tela do computador.
    \item O feedback auditivo do código projetado permite que o espectador infira
    significados dos códigos. Mesmo que de forma superficial, este recurso do livecoding
    é em muito capaz de desmistificar a programação de computadores, por muito considerada
    completamente intangível.;
    \item O código em si é um recurso poderosíssimo, que permite ao usuário controlar
    os sons produzidos amostra por amostra ou em escalas maiores, como notas, compassos, fraseados
    inteiros ou mesmo em escalas maiores de tempo, como minutos, horas, dias e semanas.
    \item O compartilhamento do código é usual, leve e eficiente como entrega completamente
    aberta de tecnologia e proposta estética.
\end{itemize}

Desta forma, iniciamos em 2011 uma linha de atuação com Livecoding que resultou em uma performance
no \emph{V Festival Contato}. Utilizamos a linguagem ChucK por apresentar os recursos que
consideramos mais apropriados, embora de forma alguma isso seja consensual na prática atual
de livecoding.

A apresentação contou com recursos adicionais para agregar interesse, como a utilização
do \emph{cowsay} (para enviar mensagens enquanto se desenrolava a música) e trajetórias
de um ponto no fundo do código para sugerir a vertigem do sono REM. Estes recursos
podem ser vistos em uso claramente nos videos demonstrativos [citar videos do vimeo].
As linhas do cowsay e o script em processing relacionados estão no Apêndice XX...

Duas pessoas executaram livecoding simultaneamente. A saber, Vilson Vieira executava
rítmos, batidas bastante marcadas que serviam como base. Renato Fabbri, autor do presente
trabalho, executava linhas fluídas quasi melódicas que formavam arcos maiores. Nos intervalos
das investidas no formato citado, havia interlúdios em que ambos se revesavam com músicas
curtas e inusitadas, como em um duelo[disponibilizar músicas em links e colocar de referencia].

[Colocar os códigos meus e do Vilson e explicar o funcionamento e uso]




  Apenas parte dos conhecedores do assunto reconhecem
  o ABT como livecoding. Alguns
  consideram a linguagem por macros mais especializadas e poderosas como
  sendo um tipo de interface escrita, nao uma linguagem de programação
  propriamente dita.

      \subsubsection{ABeatTracker}


  Manual ABT

  Linkar com ABD

      \subsubsection{Audioexperiments, Estudiolivre e Foobarbaz}

      Audioexperiments. Estúdio livre. LM





  \subsection{Música na Matéria: EKP e AHT}
      \subsubsection{Emotional Kernel Panic (EKP)}

Em 2008, colaborando intensamente com o CDTL
(Centro de Desenvolvimento de Tecnologias Livres)\footnote{foi uma associação civil formada e desmembrada em 2008 e sediada em Recife, PE}
foi lançada a ideia de utilizar o estado do sistema operacional - especialmente o kernel linux - para
geração de sons. Surge o Emotional Kernel Panic (EKP). Desde o inicio, foram definidos três finalidades
para esta exploração do SO:

\begin{itemize}
    \item Didáticos
    \item Artísticos
    \item Monitoramento do SO
\end{itemize}

http://trac.assembla.com/audioexperiments/browser/ekp-base


      \subsubsection{AirHackTable}



  \section{Web}

  Difusão de informação com ênfase na facilitação
  da apropriação de tecnologias e de instancias políticas.

      \subsection{Tecnologias sociais de alta demanda: Sitios, Conteúdos e Articulação}

      \subsubsection{Sítios}

      FDDCA

      Ferramenta de comunicação

      (Cadastro dos pontos?)

      AA, SOS, Catalogo de Ideias, etc

      Meu site pessoal


      \subsubsection{Conteúdos}

      Wiki?

      \subsubsection{Articulação}

      IRC, Emails

\subsection{Disponibilização e desenvolvimento conjunto: wikis, etherpads, AA, Trac, IRC ..}

\subsubsection{Wiki}

\subsubsection{Trac}

\subsubsection{Screencasts - Vimeo}

\subsubsection{AA}

\subsubsection{Audio Experiments (Æ)}

\subsubsection{IRC}

\subsubsection{Etherpads}

\subsubsection{Outras fontes}


\section{Materiais didáticos}

  \subsection{Tutoriais em texto e código: Filtros, Nyquist e plugins LADSPA}

Os vários materiais didáticos produzidos constam no apêndice
deste trabalho. Um único destes será exposto a seguir por sua
capacidade de agregar os conteúdos dos capítulos anterioes:
os tutoriais de filtros e amostragem.

\begin{itemize}
    \item {\bf Tutorial de python para áudio e som}

Este tutorial foi levado para Berlim no LAC 2007 e sofreu melhoras desde entao. Esta
primeira versao ficou resumida em forma de texto no EL\footnote{http://estudiolivre.org/python-e-som-tutorial}. Em 2010
a Associacao Python Brasil escolheu este trabalho, então já mais amadurecido, para ser apresentado no
FISL em Porto Alegre. Como consequencia, foi feita uma série de video-tutoriais bastante utilizados\footnote{http://estudiolivre.org/tiki-index.php?page=Video+Tutoriais}.
Este tutorial foi comentado em listas em que o autor não participa (e outras em que o autor participa).

    \item {\bf Tutoriais de filtros e amostragem via python}

Voltados para explicitar principios fundamentais de áudio, estes tutoriais
são baseados código Python e o equivalente em C. Pequenas explicações são
dadas com o intuito de orientar a exploração inteligente destes \emph{snippets}.

\emph{Teorema de Amostragem}: estes scripts visam a experimentacao inteligente com
o Teorema de Nyquist. (descricao)

\emph{Filtros}: alem da explicitação sobre as diferenças entre filtros FIR e IIR,
duas utilizações clássicas destes filtros estão implementadas: Wavelets (FIR) e Quad (IIR)

Estes códigos podem ser baixados no repositório SVN do AudioExperiments. E os textos estão
na wiki (nos digitais ou EL, recriar pois os CDTL foram apagados)

    \item {\bf Tutorial de plugins lv2}

Dadas as dificuldades que o desenvolvimento dos \emph{plugins} de áudio apresenta,
desenvolvi um tutorial passo a passo com plugins que rodam em todas as etapas.
Ele é baseado em uma interface C++ para este padrão de plugin que eh implementado
em C. Os códigos e os textos estão todos em repositório.

    \item {\bf Microtutoriais Django ~\cite{dmicrotuts}}

Estes 'microtutoriais' são baseados nos conceitos de \emph{scripts mínimos} e
\emph{alterações puntuais}. O primeiro conjunto de microtutoriais é dedicado
a reconstruir o tutorial oficial do django de forma condensada e não prolixa.
O segundo destes conjuntos é dedicado a instrumentalizar de fato o leitor com
o entendimento do funcionamento dos princípios fundamentais deste framework.

    \item {\bf Philosometrics}

Embora este não seja um trabalho didático propriamente dito, ele tem este intuito
no cerne de sua concepção e surgimento. Em decorrência dele, surgiu o  Musimetrics,
o Cinemetrics e o Literametrics. Além disso, ele é um belo exemplo da
utilização das ciências duras para a análise de ciências humanas e foi acolhido
como tal em alguns momentos.

    \item {\bf Carta mídias livres}

Texto criado em decorrência da participação da comissão de seleção no
'Prêmio Mídias Livres', a convite do Ministério da Cultura por 'notório saber'.
Esta carta é um documento único no seu conteúdo, deixando às claras
o conceito de Mídias Livres como mídias não aprisionadas pelo conceito
de propriedade, ou seja, que priorizam a sua livre circulação e a possibilidade
de geração de materiais derivados, assim como sua geração aberta ao colaborativo e comunitário.

    \item {\bf Textos de cunho sociológico, transformador}

Produção mais numerosa que as anteriores, se caracteriza por métodos não convencionais
de abordagem dos assuntos e de escrita. Em especial utiliza-se pseudônimos para
auxiliar a despersonificação, gerando textos menos presos à satisfação da auto-imagem, dente
outras qualidades. A utiliação de psudônimos é um costume muito apreciado em diversos meios,
e as pesquisas tem confirmado as vantagens que a prática apresenta e confirma\footnote{http://disqus.com/research/pseudonyms/}.

O autor destes textos se dá ao direito de não revelar seus psudônimos - embora muitos deles
sejam publicamente conhecidos - para conservar as consequências desta prática na
forma mais pura. Como comprovante desta produção, deixamos uma mensagem sobre a publicação
de textos em mídia impressa com autores internacionais,
confirmando a participação do autor desta dissertação, mas cujo
nome não consta na publicação.

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

de      fabi borges catadores@gmail.com por  riseup.net 
responder a     submidialogia@lists.riseup.net
para    submidialogia@lists.riseup.net
data    23 de agosto de 2011 12:26
assunto Re: [submidialogia] livro sub- publicação
lista de e-mails        <submidialogia.lists.riseup.net> Filtrar as mensagens dessa lista de e-mails
enviado por     lists.riseup.net
assinado por    riseup.net
cancelar inscrição      Cancelar a inscrição para essa lista de e-mails
        Importante principalmente porque você frequentemente lê mensagens com esse marcador.
ocultar detalhes 12:26 (6 minutos atrás)
entao, eu fui recebendo textos durante esse tempo,
alguns tao atrazados como dos sem satelites, mas muita gente mandou;

aqui os autores:

os internacionais nao sao muitos, o joni kempf (o que bebe ouro do hardware), o barbrook (futuros imaginarios),
Hamdy heda (da revolucao egipcia), o pedro soller (summerlab), maria llopis (pos porno),  talvez a bronac, nao entregou ainda.

dos brasileiros, renato fabri, ruiz, pasteur, morgana e caio, ju dornelles, mari marcassa, coletivo errorista, adriana velozo-drica, tiago pimentel, felipe fonseca, thiago novaes, lelex, felipe ribeiro(?), maira, verenilde,  bartolina silva, poro, vitoria amaro, fabib (eu),

entao, precisa publicar agora,
uma equipe para publicacao e,,, 

bjs
f

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

\end{itemize}

\subsection{Screencasts e outros materiais em video e em texto}

\begin{itemize}
    \item Python para áudio e música
	  Texto - palestras - videos

    \item Canal Macambira
No Macambira estão sendo produzidos materiais em screencasts sobre
diversas cenas de hackeamento.

    \begin{itemize}
	\item Live-Coding
	\item Raspagem de dados
    \end{itemize}
\end{itemize}
